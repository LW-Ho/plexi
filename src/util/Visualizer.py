__author__ = 'frank'

import logging
import socket
import time
import json
from Event import Event
import os
import zmq
import zmq.auth
from zmq.auth.thread import ThreadAuthenticator
from zmq.log.handlers import PUBHandler
import cPickle as pickle
from core.graph import DoDAG

logg = logging.getLogger('RiSCHER')
logg.setLevel(logging.DEBUG)

class FrankFancyStreamingInterface(object):
	"""
	Abstraction layer to the graph streamer as well as the central logger
	Uses direct (non encrypted) socket connection to the streaming server
	It uses an (encrypted) zeromq connection to the logger
	"""

	ConvertStatus = {
		"Cells" : {
			0 : 5, #removing
			1 : 4, #allocating
			2 : 6  #blacklisting
		}
	}

	#TODO: give every scheduler an unique topic to easily distinguish between them on the queue
	def __init__(self, name, privatekey, VisualizerHost, ZeromqHost = "*", root_id=None, empty=False):
		"""
		Calls internal methods to open the connections to both the Active Live visualizer and the logger

		:param VisualizerHost: The ip of the FrankFancyGraphStreamer
		:type VisualizerHost: str
		:param ZeromqHost: which interface the zeromq service needs to bind too ("*" for all interfaces)
		:type ZeromqHost: str
		:param KeyFolder: The folder with all the keys, as generated by generate_certificates.py
		:type KeyFolder: str
		:param root_id: the root of the network: LBR
		:type root_id: str
		:return:
		"""

		self.Active = None
		self.Logger = None
		self.EventId = 0
		self.Name = name #used as topic on the queue
		if not empty:
			if privatekey is not None:
				self._connectLogger(privatekey, Host=ZeromqHost)
			if VisualizerHost is not None:
				self._connectVisualizer(VisualizerHost, root_id)
				self.g = DoDAG(root_id, root_id)
				self.root_id = root_id

	def _connectVisualizer(self, Host, root_id):
		"""
		Connect to the Active Live Visualizer

		:param Host: The ip of the FrankFancyGraphStreamer
		:param root_id: the ip6 address of the root node of the network
		:return:
		"""
		try:
			logg.debug("Connecting Streaming Interface to Active Viewer")
			self.Active = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
			self.Active.connect((Host, 600))
			self.Active.sendall(root_id)

		except:
			logg.debug("Connection to Active Viewer failed!")
			self.Active = None

	def _connectLogger(self, key, Host="localhost"):
		"""
		Open a zeromq queue with publisher service

		:param Host: which interface the zeromq service needs to bind too ("*" for all interfaces)
		:param key: privatekey file of the scheduler
		:return:
		"""
		#TODO: error handling on certificates missing and stuff
		#TODO: expose more security options such as white/blacklisting ips and domain filtering
		self.context = zmq.Context()
		self.auth = ThreadAuthenticator(self.context)
		self.auth.start()
		self.auth.configure_curve(domain='*', location=os.path.join("keys", "public"))

		self.Logger = self.context.socket(zmq.PUB)
		scheduler_public, scheduler_secret = zmq.auth.load_certificate(os.path.join("keys", "plexi1.key_secret"))
		self.Logger.curve_secretkey = scheduler_secret
		self.Logger.curve_publickey = scheduler_public
		self.Logger.curve_server = True
		self.Logger.bind("tcp://127.0.0.1:6000")
		# raw_input("Press enter when the logger has opened subscription to us")


	def SendActiveJson(self,data):
		"""
		Sends an object as json encoded to the Active Live Viewer

		:param data: the object to be send
		:return:
		"""
		if self.Active is not None:
			logg.debug("Sending json data to Active: " + json.dumps(data))
			self.Active.sendall(json.dumps(data))

	def PublishLogging(self,LoggingName="zmq.auth", root_topic="zmq.auth"):
		"""
		Publishes the given python logger to the publishing service

		:param LoggingName: Name of the python logger service
		:type LoggingName: str
		:param root_topic: the topic given with message. is appended with .<LEVEL>
		:type root_topic: str
		:return:
		"""
		handler = PUBHandler(self.Logger)
		handler.root_topic = root_topic
		handler.formatters[logging.DEBUG] = logging.Formatter(fmt='%(asctime)s\t%(levelname)s: %(message)s', datefmt='%H:%M:%S')
		handler.formatters[logging.INFO] = logging.Formatter(fmt='%(asctime)s\t%(levelname)s: %(message)s', datefmt='%H:%M:%S')
		l = logging.getLogger(LoggingName)
		l.addHandler(handler)

	def ChangeCell(self, who, slotoffs, channeloffs, frame, ID, status):
		"""
		Notifies all active services about the changes to a cell in the schedule matrix

		:param who: The node in which the cell is changed
		:type who: :class: `node.NodeID`
		:param slotoffs: slot offset
		:param channeloffs: channel offset
		:param frame: frame name
		:param ID: local cell id
		:param status: new status of the cell
		:return:
		"""
		if self.Active is not None:
			logg.debug("Sending ChangeCell to active viewer")
			self.Active.sendall(json.dumps(["changecell",{"who": str(who), "channeloffs":channeloffs, "slotoffs":slotoffs, "frame":frame, "id":ID, "status":status}]))
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending ChangeCell to logger, EventID:" + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"		: self.EventId,
			# 	"SubjectId" 	: self.ConvertStatus["Cells"][status],
			# 	"InfoString" 	: json.dumps({"who": who, "channeloffs":channeloffs, "slotoffs":slotoffs, "frame":frame, "id":ID})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, self.ConvertStatus["Cells"][status], time.time(), json.dumps({"node_id": str(who), "channeloffs":channeloffs, "slotoffs":slotoffs, "frame":frame, "id":ID})))])

	def DumpDotData(self):
		"""
		dumps an entire dot file to the active viewer. This is not used for the logger

		:return:
		"""
		# packet = "[\"" + str(self.root_id) + " at " + time.strftime("%Y-%m-%d %H:%M:%S") + "\"," + json.dumps(dotdata) + "]"
		if self.Active is not None:
			logg.debug("Sending dotdata")
			# self.Active.sendall(bytearray("[\"" + root_id + " at " + time.strftime("%Y-%m-%d %H:%M:%S") + "\"," + dotdata + "]"))
			dotdata = self.g.draw_graph()
			self.Active.sendall(bytearray(json.dumps(["\"" + self.root_id + " at " + time.strftime("%Y-%m-%d %H:%M:%S") + "\"", dotdata])))

	def AddNode(self, node_id, parent):
		"""
		Sends a notification of joining node to the logger

		:param node_id: ip6 of the node
		:type node_id: str
		:param parent: ip6 of the parent node
		:type parent: str
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending Addnode to logger, EventID:" + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"	: self.EventId,
			# 	"SubjectId"	: 0,
			# 	"InfoString": json.dumps({"node_id" : node_id, "parent" : parent})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 0, time.time(), json.dumps({"node_id" : str(node_id), "parent" : str(parent)})))])
		if self.Active is not None:
			if parent == "root":
				self.g.attach_node(node_id)
			else:
				self.g.attach_child(node_id, parent)
			self.DumpDotData()

	def RewireNode(self, node_id, old_parent, new_parent):
		"""
		Notifies the logger of a rewire that happened in the network

		:param node_id: ip6 of the node that has rewired
		:param old_parent: ip6 of the old parent
		:param new_parent: ip6 of the new parent
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending RewireNode to logger, EventID: " + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"	: self.EventId,
			# 	"SubjectId"	: 2,
			# 	"InfoString": json.dumps({"node_id" : node_id, "old_parent" : old_parent, "new_parent" : new_parent})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 2, time.time(), json.dumps({"node_id" : str(node_id), "old_parent" : str(old_parent), "new_parent" : str(new_parent)})))])
		if self.Active is not None:
			self.g.attach_child(node_id, new_parent)
			self.DumpDotData()


	def RemoveNode(self, node_id):
		"""
		Notifies the logger of a disconnected node

		:param node_id: ip6 of the node that has disconnected
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending RemoveNode to logger, EventID: " + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"	: self.EventId,
			# 	"SubjectId"	: 1,
			# 	"InfoString": json.dumps({"node_id" : node_id})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 1, time.time(), json.dumps({"node_id" : str(node_id)})))])
		if self.Active is not None:
			self.g.detach_node(node_id)
			self.DumpDotData()

	def RegisterFrame(self, num_cells, framename):
		"""
		Notifies the logger of a new frame that is defined in the scheduler algorithm

		:param num_cells: number of cells per channel
		:param framename: unique identifieng name
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending RegisterFrame to logger, EventID: " + str(self.EventId))
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 7, time.time(), json.dumps({"cells" : num_cells, "name" : framename})))])


	def RegisterFrames(self, frames):
		if self.Active is not None:
			logg.debug("Sending RegisterFrames to Active")
			self.Active.sendall(bytearray(json.dumps(frames)))